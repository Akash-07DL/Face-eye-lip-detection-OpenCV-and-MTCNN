{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenCV_MTCNN_Face detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUF_PR2o8210"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa0XQbC7Uuz3"
      },
      "source": [
        "# Detection with MTCNN(FINAL FOR DETECTION)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjXAEAyeU1n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be0e0fa-447a-45f3-eea0-7b304517f52e"
      },
      "source": [
        "pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF0eAxRMdzHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561d169a-6b5b-453e-c6a6-a2b7f1ab3acd"
      },
      "source": [
        "pip show mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: mtcnn\n",
            "Version: 0.1.0\n",
            "Summary: Multi-task Cascaded Convolutional Neural Networks for Face Detection, based on TensorFlow\n",
            "Home-page: http://github.com/ipazc/mtcnn\n",
            "Author: IvÃ¡n de Paz Centeno\n",
            "Author-email: ipazc@unileon.es\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: opencv-python, keras\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSVgC8sJe0vI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216fdfc0-6aad-4273-f68b-9c0826e6550e"
      },
      "source": [
        "pip install dlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (19.18.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykt1Axi7e9hs"
      },
      "source": [
        "import dlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJZH4c8KeB_K",
        "outputId": "112b66b6-92f1-46fe-a5ab-9ab44971ab5e"
      },
      "source": [
        "# confirm mtcnn was installed correctly\n",
        "import mtcnn\n",
        "# print version\n",
        "print(mtcnn.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28RsXToew7DP"
      },
      "source": [
        "from mtcnn import MTCNN\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-dZ-6ofgDVq"
      },
      "source": [
        "help(MTCNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6JaY75AnZ6i"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZIc0GnD2B3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4f48ac-26f5-4406-8a09-dc9b5aa7c731"
      },
      "source": [
        "# to grab the paths to the input images in our dataset\n",
        "import os\n",
        "from imutils import paths\n",
        "print(\"[INFO] quantifying faces...\")\n",
        "imagePaths = list(paths.list_images(\"Image\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] quantifying faces...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE9u3PAin80v"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJmiojYEi9Jc"
      },
      "source": [
        "**face extractation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzRFZEYte3Fo"
      },
      "source": [
        "#output_dir = \"/content/extract\"\n",
        "\n",
        "detector = MTCNN()\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):             # /content/Image/usernamelocation0.jpg\n",
        "    \n",
        "    print(\"[INFO] processing image {}/{}\".format(i + 1,len(imagePaths)))\n",
        "    print(imagePath)\n",
        "    image = cv2.imread(imagePath)\n",
        "    #print(image.shape)\n",
        "    width = 800\n",
        "    height = 800\n",
        "    dim = (width, height)\n",
        "    face_locations = detector.detect_faces(image)\n",
        "    save_face = []\n",
        "    for face_location in face_locations:            \n",
        "        #print(len(face_locations))\n",
        "        conf = face_location['confidence']\n",
        "        \n",
        "        if conf > 0.95:\n",
        "            #print(face_location)\n",
        "            box = face_location['box']\n",
        "            x, y, w, h = box[0], box[1], box[2], box[3]\n",
        "            #cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 2), 2)\n",
        "            #cv2_imshow(image)\n",
        "            crop_face = image[y:y+h, x: x+w]\n",
        "            \n",
        "            try:\n",
        "                crop_face = cv2.resize(crop_face, (200, 200), interpolation=cv2.INTER_AREA)\n",
        "                #print(crop_face.shape)\n",
        "            except:\n",
        "                break\n",
        "            \n",
        "            crop_face = cv2.resize(crop_face, (200, 200), interpolation = cv2.INTER_AREA)\n",
        "            save_face.append(crop_face)\n",
        "            #cv2_imshow(crop_face)\n",
        "            path = '/content/faces1'\n",
        "            cv2.imwrite(os.path.join(path , str(w)+str(h)+'_faces.jpg' ), crop_face)\n",
        "             \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZUGgs108jIg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OJ2-M5w0gGO"
      },
      "source": [
        "# Final With Haar Cascade Classifier\n",
        "# size = (800,800) + grayscale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25-Qzx0E0iXA",
        "outputId": "1f090665-b038-4cee-9c8d-4d8e20baf6b8"
      },
      "source": [
        "# to grab the paths to the input images in our dataset\n",
        "print(\"[INFO] quantifying faces...\")\n",
        "imagePaths = list(paths.list_images(\"Image\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] quantifying faces...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXZJfBArD7Kw"
      },
      "source": [
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):             # /content/Image/usernamelocation0.jpg\n",
        "    print(\"[INFO] processing image {}/{}\".format(i + 1,len(imagePaths)))\n",
        "    print(imagePath)\n",
        "    image = cv2.imread(imagePath)\n",
        "    \n",
        "    print(image.shape)\n",
        "    width = 800\n",
        "    height = 800\n",
        "    dim = (width, height)\n",
        " \n",
        "# resize image\n",
        "    image1 = cv2.resize(image, dim) #interpolation = cv2.INTER_LANCZOS4)\n",
        "    image2 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    print(image2.shape)\n",
        "    cv2_imshow(image2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD-uZqBXEBDg",
        "outputId": "d5395ee4-72c1-48ad-b711-6915f9474f09"
      },
      "source": [
        "import os\n",
        "\n",
        "filenames = os.listdir(cv2.data.haarcascades)\n",
        "filenames = sorted(filenames)\n",
        "print('\\n'.join(filenames))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__.py\n",
            "__pycache__\n",
            "haarcascade_eye.xml\n",
            "haarcascade_eye_tree_eyeglasses.xml\n",
            "haarcascade_frontalcatface.xml\n",
            "haarcascade_frontalcatface_extended.xml\n",
            "haarcascade_frontalface_alt.xml\n",
            "haarcascade_frontalface_alt2.xml\n",
            "haarcascade_frontalface_alt_tree.xml\n",
            "haarcascade_frontalface_default.xml\n",
            "haarcascade_fullbody.xml\n",
            "haarcascade_lefteye_2splits.xml\n",
            "haarcascade_licence_plate_rus_16stages.xml\n",
            "haarcascade_lowerbody.xml\n",
            "haarcascade_profileface.xml\n",
            "haarcascade_righteye_2splits.xml\n",
            "haarcascade_russian_plate_number.xml\n",
            "haarcascade_smile.xml\n",
            "haarcascade_upperbody.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haWJfWNGEIIL"
      },
      "source": [
        "import cv2\n",
        "import cv2 , pafy\n",
        "import os \n",
        "import youtube_dl\n",
        "from imutils import paths\n",
        "import face_recognition\n",
        "import pickle\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from face_recognition import face_encodings\n",
        "from matplotlib import pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C53HVwhYEMwk",
        "outputId": "f49be024-a1fe-48a5-dda0-8a68a992e1f4"
      },
      "source": [
        "path = os.path.join(cv2.data.haarcascades, 'haarcascade_lip_default.xml')\n",
        "cv2.CascadeClassifier( path )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<CascadeClassifier 0x7f455a49a150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql8vxTO-ERHA"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
        "lip_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_smile.xml\")\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):                              # /content/Image/usernamelocation0.jpg\n",
        "    print(\"[INFO] processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
        "    print(imagePath)\n",
        "    image = cv2.imread(imagePath)\n",
        "    \n",
        "    print(image.shape)\n",
        "    width = 800\n",
        "    height = 800\n",
        "    dim = (width, height)\n",
        " \n",
        "# resize image\n",
        "    image1 = cv2.resize(image, dim)                                 #interpolation = cv2.INTER_LANCZOS4)\n",
        "    image2 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    print(image2.shape)\n",
        "    \n",
        "    faces = face_cascade.detectMultiScale( image2, 1.3, 5 )\n",
        "    \n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(image1,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "        \n",
        "  ###    ///////////////////////////////////////////////////////  ###########      \n",
        "        \n",
        "        #roi_gray = image2[y:y+h, x:x+w]\n",
        "        #roi_color = image1[y:y+h, x:x+w]\n",
        "        #eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "        #for (ex,ey,ew,eh) in eyes:\n",
        "         #   cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "        #lips = lip_cascade.detectMultiScale(roi_gray)\n",
        "        #for(lx,ly,lw,lh) in lips:\n",
        "         #   cv2.rectangle(roi_color,(lx,ly), (lx+lw,ly+lh),(0,255,0), 1)\n",
        "    #plt.imshow(image[0])\n",
        "    \n",
        "#####    //////////////////////////////////////////////////   ###############\n",
        "\n",
        "    #cv2_imshow(image1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z198GoKNfNvC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}